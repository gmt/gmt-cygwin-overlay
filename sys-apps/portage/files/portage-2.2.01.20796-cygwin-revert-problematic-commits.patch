Revert various parallel ebuild-helper commits

This reverts (or attempts to) the following commits:

o prepstrip: make splitdebug/installsources parallel safe
  (4941c3c674400116f118a9c75b520c3fd1a25490)
o prepstrip: disable parallel for splitdebug, etc..
  (b4fba3e9fa2e285244de491f57700978158c1838)
o prepstrip/ecompressdir: parallelize operations
  (76939c46aa2817bdbcea703432c52e5aa04160f9)

bin/ebuild-helpers/prepstrip had some pretty ugly merge conflicts
when reverting these.  The first two, above, are only reverted because
by so doing we simplify the reversion of the third which is the real
"issue".  It may well be that my merges aren't correct here and I'm
introducing some bugs, which may not be revealing themselves on
cygwin due to not being an elf platform.

Why revert?  Well I don't know -- it's obvious the parallel multijob.* stuff
is not working right as-is on Cygwin although the true severity of the issue
isn't clear to me yet.

The behavior is, a lot of error messages about "failed to read" and "failed to send"
coming from, I think, multijob_finish_one and wherever it is writes occur onto the
other ends of those pipes -- I haven't even looked into it enough to understand
where that is yet, tbh.

Perhaps it's a problem with cygwin or with bash, or something non portable in the
scripts....   Perhaps the error messages are actually not all that important
and everything works fine.  As I said, I just don't know yet.  For the moment, I
simply wanted to get things working, so I can move forward with other things, while
I investigate the matter more thorougly.

For now, I figure it's better to have a working-but-slow serialized portage than
a portage that's fast and possibly broken.

diff --git a/bin/ebuild-helpers/ecompressdir b/bin/ebuild-helpers/ecompressdir
index bf76b1f..539bf3b 100755
--- a/bin/ebuild-helpers/ecompressdir
+++ b/bin/ebuild-helpers/ecompressdir
@@ -2,7 +2,7 @@
 # Copyright 1999-2011 Gentoo Foundation
 # Distributed under the terms of the GNU General Public License v2
 
-source "${PORTAGE_BIN_PATH:-@PORTAGE_BASE@/bin}"/helper-functions.sh
+source "${PORTAGE_BIN_PATH:-@PORTAGE_BASE@/bin}"/isolated-functions.sh
 
 if [[ -z $1 ]] ; then
 	helpers_die "${0##*/}: at least one argument needed"
@@ -125,16 +125,6 @@ ret=0
 
 rm -rf "${T}"/ecompress-skip
 
-decompressors=(
-	".Z"    "gunzip -f"
-	".gz"   "gunzip -f"
-	".bz2"  "bunzip2 -f"
-	".xz"   "unxz -f"
-	".lzma" "unxz -f"
-)
-
-multijob_init
-
 for dir in "$@" ; do
 	dir=${dir#/}
 	dir="${ED}${dir}"
@@ -155,21 +145,9 @@ for dir in "$@" ; do
 	find "${dir}" -type f -name '*.ecompress.file' -print0 | ${XARGS} -0 rm -f
 
 	# not uncommon for packages to compress doc files themselves
-	for (( d = 0; d < ${#decompressors[@]}; d += 2 )) ; do
-		# It's faster to parallelize at this stage than to try to
-		# parallelize the compressors.  This is because the find|xargs
-		# ends up launching less compressors overall, so the overhead
-		# of forking children ends up dominating.
-		(
-		multijob_child_init
-		funk_up_dir "decompress" "${decompressors[i]}" "${decompressors[i+1]}"
-		) &
-		multijob_post_fork
-		: $(( ret |= $? ))
-	done
-
-	multijob_finish
-	: $(( ret |= $? ))
+	funk_up_dir "decompress" ".Z" "gunzip -f"
+	funk_up_dir "decompress" ".gz" "gunzip -f"
+	funk_up_dir "decompress" ".bz2" "bunzip2 -f"
 
 	# forcibly break all hard links as some compressors whine about it
 	find "${dir}" -type f -links +1 -exec env file="{}" sh -c \
diff --git a/bin/ebuild-helpers/prepstrip b/bin/ebuild-helpers/prepstrip
index 1ee1c96..c4a7600 100755
--- a/bin/ebuild-helpers/prepstrip
+++ b/bin/ebuild-helpers/prepstrip
@@ -2,7 +2,7 @@
 # Copyright 1999-2012 Gentoo Foundation
 # Distributed under the terms of the GNU General Public License v2
 
-source "${PORTAGE_BIN_PATH:-@PORTAGE_BASE@/bin}"/helper-functions.sh
+source "${PORTAGE_BIN_PATH:-@PORTAGE_BASE@/bin}"/isolated-functions.sh
 
 # avoid multiple calls to `has`.  this creates things like:
 #   FEATURES_foo=false
@@ -62,13 +62,6 @@ prepstrip_sources_dir=${EPREFIX}/usr/src/debug/${CATEGORY}/${PF}
 type -P debugedit >/dev/null && debugedit_found=true || debugedit_found=false
 debugedit_warned=false
 
-multijob_init
-
-# Setup $T filesystem layout that we care about.
-tmpdir="${T}/prepstrip"
-rm -rf "${tmpdir}"
-mkdir -p "${tmpdir}"/{inodes,splitdebug,sources}
-
 # Usage: inode_var_name: <file>
 inode_file_link() {
 	echo -n "${tmpdir}/inodes/"
@@ -101,11 +94,11 @@ save_elf_sources() {
 	buildid=$(debugedit -i \
 		-b "${WORKDIR}" \
 		-d "${prepstrip_sources_dir}" \
-		-l "${tmpdir}/sources/${x##*/}.${BASHPID}" \
+		-l "${T}"/debug.sources \
 		"${x}")
 }
 
-# Usage: save_elf_debug <elf> [splitdebug file]
+# Usage: save_elf_debug <elf>
 save_elf_debug() {
 	${FEATURES_splitdebug} || return 0
 
@@ -114,7 +107,6 @@ save_elf_debug() {
 	# twice in this path) in order for gdb's debug-file-directory
 	# lookup to work correctly.
 	local x=$1
-	local splitdebug=$2
 	local y=${ED}usr/lib/debug/${x:${#D}}.debug
 
 	# dont save debug info twice
@@ -126,8 +118,8 @@ save_elf_debug() {
 	if [[ -f ${inode} ]] ; then
 		ln "${inode}" "${y}"
 	else
-		if [[ -n ${splitdebug} ]] ; then
-			mv "${splitdebug}" "${y}"
+		if [[ -e ${T}/prepstrip.split.debug ]] ; then
+			mv "${T}"/prepstrip.split.debug "${y}"
 		else
 			local objcopy_flags="--only-keep-debug"
 			${FEATURES_compressdebug} && objcopy_flags+=" --compress-debug-sections"
@@ -179,13 +171,11 @@ process_elf() {
 
 		# see if we can split & strip at the same time
 		if [[ -n ${SPLIT_STRIP_FLAGS} ]] ; then
-			local shortname="${x##*/}.debug"
-			local splitdebug="${tmpdir}/splitdebug/${shortname}.${BASHPID}"
 			${STRIP} ${strip_flags} \
-				-f "${splitdebug}" \
-				-F "${shortname}" \
+				-f "${T}"/prepstrip.split.debug \
+				-F "${x##*/}.debug" \
 				"${x}"
-			save_elf_debug "${x}" "${splitdebug}"
+			save_elf_debug "${x}"
 		else
 			save_elf_debug "${x}"
 			${STRIP} ${strip_flags} "${x}"
@@ -201,10 +191,8 @@ if ! ${RESTRICT_binchecks} && ! ${RESTRICT_strip} ; then
 	# We need to do the non-stripped scan serially first before we turn around
 	# and start stripping the files ourselves.  The log parsing can be done in
 	# parallel though.
-	log=${tmpdir}/scanelf-already-stripped.log
-	scanelf -yqRBF '#k%F' -k '!.symtab' "$@" | sed -e "s#^${ED}##" > "${log}"
-	(
-	multijob_child_init
+	log=$T/scanelf-already-stripped.log
+	scanelf -yqRBF '#k%F' -k '!.symtab' "$@" | sed -e "s#^${ED}##" > "$log"
 	qa_var="QA_PRESTRIPPED_${ARCH/-/_}"
 	[[ -n ${!qa_var} ]] && QA_PRESTRIPPED="${!qa_var}"
 	if [[ -n ${QA_PRESTRIPPED} && -s ${log} && \
@@ -225,8 +213,6 @@ if ! ${RESTRICT_binchecks} && ! ${RESTRICT_strip} ; then
 	else
 		rm -f "${log}"
 	fi
-	) &
-	multijob_post_fork
 fi
 
 # Now we look for unstripped binaries.
@@ -239,10 +225,8 @@ do
 		banner=true
 	fi
 
-	(
-	multijob_child_init
-	f=$(file "${x}") || exit 0
-	[[ -z ${f} ]] && exit 0
+	f=$(file "${x}") || continue
+	[[ -z ${f} ]] && continue
 
 	if ! ${SKIP_STRIP} ; then
 		# The noglob funk is to support STRIP_MASK="/*/booga" and to keep
@@ -289,15 +273,8 @@ do
 	if ${was_not_writable} ; then
 		chmod u-w "${x}"
 	fi
-	) &
-	multijob_post_fork
 done
 
-# With a bit more work, we could run the rsync processes below in
-# parallel, but not sure that'd be an overall improvement.
-multijob_finish
-
-cd "${tmpdir}"/sources/ && cat * > "${tmpdir}/debug.sources" 2>/dev/null
 if [[ -s ${tmpdir}/debug.sources ]] && \
    ${FEATURES_installsources} && \
    ! ${RESTRICT_installsources} && \
diff --git a/bin/helper-functions.sh b/bin/helper-functions.sh
deleted file mode 100644
index c7400fa..0000000
--- a/bin/helper-functions.sh
+++ /dev/null
@@ -1,90 +0,0 @@
-#!/bin/bash
-# Copyright 1999-2012 Gentoo Foundation
-# Distributed under the terms of the GNU General Public License v2
-
-# For routines we want to use in ebuild-helpers/ but don't want to
-# expose to the general ebuild environment.
-
-source "${PORTAGE_BIN_PATH:-/usr/lib/portage/bin}"/isolated-functions.sh
-
-#
-# API functions for doing parallel processing
-#
-numjobs() {
-	# Copied from eutils.eclass:makeopts_jobs()
-	local jobs=$(echo " ${MAKEOPTS} " | \
-		sed -r -n 's:.*[[:space:]](-j|--jobs[=[:space:]])[[:space:]]*([0-9]+).*:\2:p')
-	echo ${jobs:-1}
-}
-
-multijob_init() {
-	# Setup a pipe for children to write their pids to when they finish.
-	mj_control_pipe=$(mktemp -t multijob.XXXXXX)
-	rm "${mj_control_pipe}"
-	mkfifo "${mj_control_pipe}"
-	redirect_alloc_fd mj_control_fd "${mj_control_pipe}"
-	rm -f "${mj_control_pipe}"
-
-	# See how many children we can fork based on the user's settings.
-	mj_max_jobs=$(numjobs)
-	mj_num_jobs=0
-}
-
-multijob_child_init() {
-	trap 'echo ${BASHPID} $? >&'${mj_control_fd} EXIT
-	trap 'exit 1' INT TERM
-}
-
-multijob_finish_one() {
-	local pid ret
-	read -r -u ${mj_control_fd} pid ret
-	: $(( --mj_num_jobs ))
-	return ${ret}
-}
-
-multijob_finish() {
-	local ret=0
-	while [[ ${mj_num_jobs} -gt 0 ]] ; do
-		multijob_finish_one
-		: $(( ret |= $? ))
-	done
-	# Let bash clean up its internal child tracking state.
-	wait
-	return ${ret}
-}
-
-multijob_post_fork() {
-	: $(( ++mj_num_jobs ))
-	if [[ ${mj_num_jobs} -ge ${mj_max_jobs} ]] ; then
-		multijob_finish_one
-	fi
-	return $?
-}
-
-# @FUNCTION: redirect_alloc_fd
-# @USAGE: <var> <file> [redirection]
-# @DESCRIPTION:
-# Find a free fd and redirect the specified file via it.  Store the new
-# fd in the specified variable.  Useful for the cases where we don't care
-# about the exact fd #.
-redirect_alloc_fd() {
-	local var=$1 file=$2 redir=${3:-"<>"}
-
-	if [[ $(( (BASH_VERSINFO[0] << 8) + BASH_VERSINFO[1] )) -ge $(( (4 << 8) + 1 )) ]] ; then
-			# Newer bash provides this functionality.
-			eval "exec {${var}}${redir}'${file}'"
-	else
-			# Need to provide the functionality ourselves.
-			local fd=10
-			while :; do
-					# Make sure the fd isn't open.  It could be a char device,
-					# or a symlink (possibly broken) to something else.
-					if [[ ! -e /dev/fd/${fd} ]] && [[ ! -L /dev/fd/${fd} ]] ; then
-							eval "exec ${fd}${redir}'${file}'" && break
-					fi
-					[[ ${fd} -gt 1024 ]] && die "redirect_alloc_fd failed"
-					: $(( ++fd ))
-			done
-			: $(( ${var} = fd ))
-	fi
-}
